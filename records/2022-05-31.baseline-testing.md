# Secrets in Notify

Date: 2022-05-21

## Status

**DRAFT**

## Context

We need to collect performance metrics that are more closely aligned with current and predicted system usage patterns, in order to help tune and scale Notify.
We would also like to have a standard procedure for evaluating the affect of code optimizations on system performance.

## Methods and libraries

This section enumerates a few methods and libraries to help understand the rest of
the document to casual readers.

### [Hasura](https://hasura.io/)

Hasura is a graphQL / postgreSQL engine we have connected to our database that we can use for one-off queries.

### [locust](https://locust.io/)

Locust is a widely-used python-based tool for performance testing.

### Message priorities

Messages can have priority "bulk", "normal", or "priority".

## Current usage patterns

### Basic usage types

* newsletters or other bulk messages: a message sent at the same time to a large number of users. Usually not time sensitive.

* personal messages: messages sent to one user. For example, confirmation of the user submitting a form. These should be delivered relatively quickly but can likely wait a minute or two.

* multi-factor authentication (MFA): services sending users a log in code. In this situation the user is waiting for the message to arrive before continuing with their activity, so speed of delivery is critical.


By the numbers, most of our notifications are sent in large bursts. Occasionally two or more services will simultaneously be doing a large send. At the same time other services are trickling through a small number of messages (including MFA messages).

### Useful Data

* monthly volumes of sms / email, and priority / normal / bulk and month over month growth
  * use these to get rough idea of proportion of different types of data
* historical burst sizes and composition
* "bad days" - perhaps the busiest hour long period in each month?
  * use this to get an idea of how much total traffic to baseline

Some initial queries at
https://docs.google.com/spreadsheets/d/1G8Eno3FkISdaZf_ySgDHiURnUZyJiz0CqErqC7iRCLk

## Possible tests

* run an hour long test, with twice the data of the busiest time (or perhaps twice rounded up to the nearest 100K)
* use the average monthly proportion of different types of data
* question: Do we worry about SMS? Can we assume that they'll spend the same amount of time in Notify as emails?

## Other questions

* Where should the test code live? (api / attic / performance-test-results)
* if our tests are harder than the worst hour then we should expect real-life results to be better than the test results. We should verify this on some sort of regular basis. 

## Recommandations

TBD

## Consequences

_TODO: Describe foreseen and felt consequences of the decision (possible after 1-3 months)._
