# Move the Notify API from Kubernetes to AWS Lambda

Date: 2021-08-16

## Status

**PROPOSED**

## Context

The SRE team is encouraging us to move the Notify API from Kubernetes to AWS Lambda. AWS Lambda functions allow code to be run in a highly scalable way - we can have hundreds of lambda functions running simulateously, and this auto-scales to meet the number of requests being made to the API. The benefits of doing this are thought to be the following:

- less complexity for the Notify team to manage, compared to Kubernetes
- more scalable API
- less costly compared to kubernetes + Amazon EKS

At the time when Notify was being deployed by CDS, AWS Lambda had a smaller maximum size for a lambda function. Notify was over this limit and so @max deployed it a different way.

Since then, AWS has added support for Docker images and increased the size limit for these to 10 GB. This means it is now possible to deploy the Notify API as a Lambda function.

CDS has now used lambda functions to run the covid alert metrics collection and aggregation (https://github.com/cds-snc/covid-alert-metrics-terraform/tree/main/aws). Lambda functions helped that part of the service to scale well.

## Proposed architecture

AWS Lambda + API Gateway

## Additional considerations

AWS Lambda functions exhibit "cold-start" behaviour, where they can take more than 1 second to respond if they [have not been invoked recently](https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/#:~:text=The%20duration%20of%20a%20cold,test%20functions%20than%20production%20workloads). If we do not mitigate this, the admin site will appear unresponsive at times. AWS has a feature to mitigate this, called [provisioned concurrency](https://aws.amazon.com/blogs/compute/new-for-aws-lambda-predictable-start-up-times-with-provisioned-concurrency/).

Another consideration will be the effects on other parts of Notify. If the API can scale much better than in the past, will some other parts of the system become overloaded? The may not be an issue because we queue our upcoming jobs with Celery, but we should do significant load testing before running lambda functions in production.

Lambdas may make local testing a bit more difficult by forcing us to either wire up some docker containers using aws-lambda-rie or use AWS SAM to orchestrate the work. With Kubernetes, testing locally is easier since docker desktop can be used to bring up the test system.

## Load testing results

We ran a load test where we simulated 5,500 requests per minute to the api using locust, to see if the new lambda deployment could meet existing peak loads. The these requests were made to the `/v2/notifications/email` endpoint and were split into 2 services to make the test more realistic. Here are the reports:
- [Report for Service 1](https://htmlpreview.github.io/?https://raw.githubusercontent.com/cds-snc/notification-adr/move-to-lambda/records/attachments/report_1629229241.7761497.html)
- [Report for Service 2](https://htmlpreview.github.io/?https://raw.githubusercontent.com/cds-snc/notification-adr/move-to-lambda/records/attachments/report_1629229258.5504797.html)

There were 0 failures, and median response time was 110ms for both services and 99th percentile response time was 250ms for Service 1 and 230ms for Service 2 over a 7 minute test.

We had provisioned 2 concurrent lambda functions to always run, and these handled about 10% of the requests, with the other 90% going to lambda functions that were provisioned on-demand.

These results demonstrate that the lambda deployment should be able to handle the current peak loads.
## Decision

TBD based on load testing results

## Consequences

_To be discussed._
