# Current Manifests CI/CD

Date: 2024-06-04

## Status

**DRAFT**.

## Related ADRs

For information on how manifest rollouts are done using GitHub ARC Runners please see this ADR:
[Private EKS Cluster](2024-02-15.private-eks-cluster.md)

## Context

The Notify CI/CD is currently a complex setup consisting of several different release paradigms. This ADR outlines the current state of the Notify CI/CD as well as the problems associated with this and proposes options for simplifying the CI/CD while also improving the consistency of the release process.

## Problems

- Staging and Production do not adhere to the same release process.
- In Manifests, there is no ability to preview changes being applied to production.
- In Manifests, when deploying to staging, explicitly tagged docker images get replaced with "latest".
- The release process is different between infrastructure (Terraform) and the application (Manifests).
- Using self hosted Github runners introduces complexity and additional work.

## Current State

### Staging

#### Individual Application Rollouts

When deploying a new version of the application components (admin/api/document-download etc), the release to staging is kicked off at the application repository level when the docker image is built. The docker image tag is based on the first 7 digits of the github runner sha, and also tags this build as latest. The docker build and push workflow makes a curl call to invoke a corresponding workflow in the notification-manifests repository  (which runs on the internal Github runners) passing the new docker tag to have it deployed to staging. 

The manifests rollout workflow receives the new image tag and performs a manual patch of the existing deployment:

```shell
kubectl set image deployment.apps/api api=$DOCKER_SLUG:$DOCKER_TAG -n=notification-canada-ca
```

##### Admin Pull Request and Merge To Main

![Staging Admin Current CICD](./diagrams/2024-06-04.manifests-current-cicd/current-admin-pr.png)

##### API Pull Request and Merge To Main

![Staging API Current CICD](./diagrams/2024-06-04.manifests-current-cicd/current-api-pr.png)

##### Document Download API Pull Request and Merge To Main

![Staging Document Download API Current CICD](./diagrams/2024-06-04.manifests-current-cicd/current-dd-api-pr.png)

##### Documentation Pull Request and Merge To Main

![Staging Documentation Current CICD](./diagrams/2024-06-04.manifests-current-cicd/current-documentation-pr.png)

#### Kustomize/Helmfile/Manifests Pull Request and Merge To Main

When a global manifests rollout is performed by the merge to main (staging) github workflow, all of the Kustomize code is deployed.

```shell
notification-manifests/env/staging kubectl apply -k .
```

![Staging Manifests Current CICD](./diagrams/2024-06-04.manifests-current-cicd/current-manifests-pr.png)

##### Terraform Pull Request and Merge To Main

![Staging Terraform Current CICD](./diagrams/2024-06-04.manifests-current-cicd/current-terraform-pr.png)

### Production

#### Individual Application Rollouts

This concept does not exist for production. We only rollout all of Kustomize.

#### Global Manifests Rollouts

The Notify PR Bot generates an auto-pr on every merge to main in each of the application Github repositories (see above). The PR bot does not touch the helmfile side of things, so a global helmfile apply is done when a production release is executed.

#### Kustomize/Helmfile/Manifests Production Release

![Production Manifests Release](./diagrams/2024-06-04.manifests-current-cicd/current-manifests-pr.png)

##### Terraform Production Release

![Production Terraform Release](./diagrams/2024-06-04.manifests-current-cicd/current-terraform-release.png)

### Problems

#### Two Different Deployment Technologies

We are currently managing two different Kubernetes deployment methods with Kustomize and Helmfile. It would be beneficial to have everything under one technology.

#### Staging Releases

Because we do not actually update any manifests code when doing an individual application rollout, we lose all context of which version we should be using when we do a global manifest rollout with merge to main (staging). To overcome this, the staging Kustomize code is set to always use the "latest" tag. This means when we apply kustomize the explicitly versioned docker tag is overwritten with "latest". This works because the docker build and push job for each application tags as both latest and the github sha. It is however not ideal since it becomes difficult to track versions in staging, and also creates a delta between how staging and production releases are handled through release pipelines.

This issue is a problem regardless of whether we use Kustomize or Helmfile.

#### Helmfile Image Versions

For helmfile releases, we are relying on the helmfile logic to set the image versions in the overrides. For example, we may have something like the code block below, which hard codes the tag for production, but accepts either an environment variable or will default to "latest" if it does not exist.

```yaml
      {{ if eq .Environment.Name "production" }}
      image:
        tag: release1.24
      {{ else }}
      image:
        tag: {{ env "DOCKER_TAG" | default "latest" }}
      {{ end }}
```

This is an ok solution, but it's not ideal to have to modify the individual override files to set image versions for production manually. It would be ideal to have this done automatically like with the PR bot.

## Options

Because Helmfile has been identified as a long term goal to migrate GC Notify to, the options below will all involve moving the Kustomize code to Helmfile.

### Option 1: Migrate Everything to Helmfile Keeping the Existing CI/CD Processes

The first option is to simply move Notify to helmfile, and adapt the existing CI/CD process. This will be a relatively easy change as most of this work has been completed in a manifests branch. The Notify PR bot will have to be modified to change the image tag in the overrides files of helmfile instead of the Kustomization.yaml file.

The staging deployments would remain exactly the same as they are now.

#### Diagram

![Production CICD Option 1](./diagrams/2024-06-04.manifests-current-cicd/cicd-option1.png)

#### Pros

- Least effort
- Consolidates all Kubernetes resources to a single technology
- Introduces the ability to add "Diff" previews to Notify Applications on manifests PRs

#### Cons

- Does not solve the release process differences between staging and production

### Option 2: Per-Environmnent Centralized Image Version File

The second option is to try and overhaul the CI/CD process in staging to make it more consistent with production, while also maintaining the flexibility of rapid deployments to staging. We could create a github action in each notification-x repo that automatically modifies a centralized <environment>\_image_versions.json file. When this change is merged to main, a manifests job would trigger a new deploy to either staging or production.

#### Diagram

![Staging/Production CICD Option 2](./diagrams/2024-06-04.manifests-current-cicd/cicd-option2a.png)

#### Pros

- Consolidates all Kubernetes resources to a single technology
- Introduces the ability to add "Diff" previews to Notify Applications on manifests PRs
- Staging and Production have the same release process

#### Cons

- More complex - will need to enable/disable branch protection when updating the image.json

## Additional considerations

These are high level concepts only. In addition to the release processes above, we would have to integrate helmfile diff into the PRs, which currently must be done in manifests only. We are working on a solution that will allow Github to hit the private EKS cluster directly via VPN which would reduce a lot of complexity around this.

## Decision

_TODO: Describe the way forward._

## Consequences

_TODO: Describe foreseen and felt consequences of the decision (possible after 1-3 months)._
