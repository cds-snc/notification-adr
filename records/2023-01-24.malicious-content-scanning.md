# Malicious Content Scanning

Date: 2023-01-24

## Status

**DRAFT**.

_VALUES: (DRAFT, IN REVIEW, APPROVED, REJECTED)_

## Context

[security review suggested we should do this]
As a result of a 

[I tried getting scan-files to run on our s3 bucket, that didn't work because we are using a separate encryption key for each file to prevent a user from being able to download other people's files]

[I am now calling the scan files api directly. this can take a few seconds to return a response, and time increases as file size increases]

[I was planning to use the async library in python to create a new process to call the scan-files api. then once the result is returned, I can then write that result to the s3 object as a tag which can be read later.]

[it looks like it is not possible to use async code or create background processes inside flask, so now there are a few possible next steps.]
It seems that it is [not possible to create background processes inside flask](https://flask.palletsprojects.com/en/2.2.x/async-await/#background-tasks).

## Options

Here are some of the options for scanning email attachments with the scan-files project.

### Migrate Document Download API from Flask to Quart

Flask does not have good async support, and [they suggest using Quart for better async support](https://flask.palletsprojects.com/en/2.2.x/async-await/#when-to-use-quart-instead). 

It does seem like Quart [adds support for background tasks](https://quart.palletsprojects.com/en/latest/how_to_guides/background_tasks.html) and would solve our problem.

It seems like migrating from Flask to [Quart](https://github.com/pallets/quart) is not very difficult (see [quart docs](https://quart.palletsprojects.com/en/latest/how_to_guides/flask_migration.html)).

### Duplicate S3 bucket

The scan-files project comes with a terraform module that triggers a scan of newly created S3 objects in a bucket it is told to watch. The publicly accessible S3 bucket we are currently using to store file attachments won't work, since it these file are each encrypted with a unique key and scan-files tf module doens not support this. But we could create a duplicate s3 bucket that is not publicly available containing unencrypted versions of these files.

That would work but we would need to be able to map files from the public s3 bucket to the private bucket, and we would need to enforce the same retention/deletion policies on both buckets.

### Implement a new queue in Document Download API to start background tasks

Use celery to store a queue of tasks to query the scan-files API and add a tag with the scan verdict to the S3 object.

### Create a new api/lambda function to perform the task 

Another possibility?

## Additional considerations

_TODO: Describe extras in here._

## Decision

_TODO: Describe the way forward._

## Consequences

_TODO: Describe foreseen and felt consequences of the decision (possible after 1-3 months)._
